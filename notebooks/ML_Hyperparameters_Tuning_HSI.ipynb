{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDbbDF5f3OGQe6R/DwRgB1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Hyperparameters Tuning for ML Models\n","\n","The overall goal of the notebook is to **build and compare various machine learning models for regression tasks** using Python's scikit-learn library.\n","\n","The specific models implemented and compared include Random Forest Regression , Support Vector Regression, and XGBoost regression. The notebook provides functions to perform hyperparameter tuning and cross-validation to assess model performance. Additionally, the notebook provides a function to load data from a CSV file and separate the features and target columns, and function for split the data into train and test, making it easier to use the implemented models with new datasets."],"metadata":{"id":"1fcayoSW8c6u"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVR\n","from sklearn.model_selection import GridSearchCV, cross_validate\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"SZEMCNzg3tOl","executionInfo":{"status":"ok","timestamp":1677429409544,"user_tz":-120,"elapsed":2404,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def load_data(csv_path, feature_col_start, feature_col_end, target_col):\n","    \"\"\"\n","    Load a CSV file into a Pandas DataFrame,drop Nan, and separate the feature and target columns.\n","\n","    Parameters:\n","        csv_path (str): Path to the CSV file to load.\n","        feature_col_start, feature_col_end, (ints): Range of column indices to use as features.\n","        target_col (str or int): Name or index of the column to use as target.\n","\n","    Returns:\n","        new_df: A df containing the features + labels DataFrame.\n","    \"\"\"\n","    # Load CSV into a Pandas DataFrame\n","    df = pd.read_csv(csv_path)\n","\n","    # drop nan\n","    df = df.dropna()\n","\n","    # Extract the feature and target columns\n","    new_df = df[df.columns[feature_col_start: feature_col_end]]\n","    new_df[target_col] = df[target_col]\n","\n","    return new_df"],"metadata":{"id":"5-V4jMk73wds","executionInfo":{"status":"ok","timestamp":1677429409544,"user_tz":-120,"elapsed":5,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def split_data(df, target_col, test_size=0.3, random_state=42):\n","    \"\"\"\n","    Splits the input DataFrame into training and testing sets.\n","    \n","    Parameters:\n","    -----------\n","    df (pandas DataFrame): The input DataFrame containing the features and target variable.\n","    target_col (str): The name of the target column in the DataFrame.\n","    test_size (float, optional): The proportion of the data to use for testing (default=0.3).\n","    random_state (int, optional): The random seed to use for the train-test split (default=42).\n","        \n","    Returns:\n","    --------\n","    X_train (pandas DataFrame): The training set features.     \n","    X_test (pandas DataFrame): The testing set features.        \n","    y_train (pandas Series): The training set target variable.\n","    y_test (pandas Series): The testing set target variable.\n","    \"\"\"\n","    # Extract the features and target variable from the DataFrame\n","    X = df.drop(columns=[target_col])\n","    y = df[target_col]\n","    \n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n","    \n","    # Return the training and testing sets\n","    return X_train, X_test, y_train, y_test"],"metadata":{"id":"6scldQhz9PWW","executionInfo":{"status":"ok","timestamp":1677429409545,"user_tz":-120,"elapsed":6,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Hyperparameters search\n"],"metadata":{"id":"8LqvFAkY9vDf"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"NPIrl7vB3nMJ","executionInfo":{"status":"ok","timestamp":1677429409545,"user_tz":-120,"elapsed":5,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"outputs":[],"source":["def rf_regression(x_train, y_train):\n","\n","  # Define the hyperparameters to search over\n","  param_grid = {\n","        'n_estimators': [50, 100, 200],\n","        'max_depth': [None, 5, 10],\n","        'min_samples_split': [2, 5, 10],\n","        'min_samples_leaf': [1, 2, 4],\n","        'max_features': ['auto', 'sqrt', 'log2'],\n","        'bootstrap': [True, False],\n","        'oob_score': [True, False],\n","        'warm_start': [True, False],\n","        'ccp_alpha': [0, 0.1, 0.5, 1],\n","        'max_samples': [None, 0.5, 0.7, 0.9]\n","  }\n","    \n","  # Create the random forest regression model\n","  rf = RandomForestRegressor()\n","  \n","  # Perform a grid search over the hyperparameters using cross-validation\n","  grid_search = GridSearchCV(rf, param_grid, cv=5,verbose=2)\n","  grid_search.fit(x_train, y_train)\n","  \n","  # Print the best hyperparameters and their corresponding score\n","  print(f\"Best hyperparameters: {grid_search.best_params_}\")\n","  print(f\"Best score: {grid_search.best_score_}\")\n","\n","  # Use cross-validation to calculate MSE, R2, and MAE\n","  scoring = ['neg_mean_squared_error', 'r2', 'neg_mean_absolute_error']\n","  cv_results = cross_validate(grid_search.best_estimator_, x_train, y_train, cv=3, scoring=scoring)\n","  \n","  # Print the mean and standard deviation of each metric across the 5 folds\n","  mse_mean = -1 * cv_results['test_neg_mean_squared_error'].mean()\n","  mse_std = cv_results['test_neg_mean_squared_error'].std()\n","  r2_mean = cv_results['test_r2'].mean()\n","  r2_std = cv_results['test_r2'].std()\n","  mae_mean = -1 * cv_results['test_neg_mean_absolute_error'].mean()\n","  mae_std = cv_results['test_neg_mean_absolute_error'].std()\n","  \n","  print(f\"MSE: {mse_mean:.2f} +/- {mse_std:.2f}\")\n","  print(f\"R2: {r2_mean:.2f} +/- {r2_std:.2f}\")\n","  print(f\"MAE: {mae_mean:.2f} +/- {mae_std:.2f}\")\n","  \n","  # Return a ready-to-use model with the best hyperparameters\n","  best_model = grid_search.best_estimator_\n","  return best_model\n"]},{"cell_type":"code","source":["def svm_regression(x_train, y_train):\n","    # Define the hyperparameters to search over\n","    param_grid = {\n","        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","        'C': [0.1, 1, 10, 100],\n","        'gamma': ['scale', 'auto'] + [0.1, 1, 10],\n","        'epsilon': [0.1, 0.01, 0.001],\n","        'degree': [2, 3, 4],\n","        'coef0': [-1, 0, 1]\n","    }\n","    \n","    # Create the SVM regression model\n","    svm = SVR()\n","    \n","    # Perform a grid search over the hyperparameters using cross-validation\n","    grid_search = GridSearchCV(svm, param_grid, cv=5,verbose=2)\n","    grid_search.fit(x_train, y_train)\n","    \n","    # Print the best hyperparameters and their corresponding score\n","    print(f\"Best hyperparameters: {grid_search.best_params_}\")\n","    print(f\"Best score: {grid_search.best_score_}\")\n","\n","        # Use cross-validation to calculate MSE, R2, and MAE\n","    scoring = ['neg_mean_squared_error', 'r2', 'neg_mean_absolute_error']\n","    cv_results = cross_validate(grid_search.best_estimator_, x_train, y_train, cv=3, scoring=scoring)\n","    \n","    # Print the mean and standard deviation of each metric across the 5 folds\n","    mse_mean = -1 * cv_results['test_neg_mean_squared_error'].mean()\n","    mse_std = cv_results['test_neg_mean_squared_error'].std()\n","    r2_mean = cv_results['test_r2'].mean()\n","    r2_std = cv_results['test_r2'].std()\n","    mae_mean = -1 * cv_results['test_neg_mean_absolute_error'].mean()\n","    mae_std = cv_results['test_neg_mean_absolute_error'].std()\n","    \n","    print(f\"MSE: {mse_mean:.2f} +/- {mse_std:.2f}\")\n","    print(f\"R2: {r2_mean:.2f} +/- {r2_std:.2f}\")\n","    print(f\"MAE: {mae_mean:.2f} +/- {mae_std:.2f}\")\n","    \n","    # Return a ready-to-use model with the best hyperparameters\n","    best_model = grid_search.best_estimator_\n","    return best_model"],"metadata":{"id":"XQXeJuXF43Gp","executionInfo":{"status":"ok","timestamp":1677429410206,"user_tz":-120,"elapsed":3,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def xgb_regression(x_train, y_train):\n","    # Define the hyperparameters to search over\n","    param_grid = {\n","    'learning_rate': [0.01, 0.1, 0.5],\n","    'max_depth': [3, 5, 7],\n","    'n_estimators': [50, 100, 200],\n","    'min_child_weight': [1, 3, 5],\n","    'subsample': [0.5, 0.7, 1.0],\n","    'colsample_bytree': [0.5, 0.7, 1.0],\n","    'gamma': [0, 0.1, 0.5]}\n","    \n","    # Create the XGB regression model\n","    xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n","\n","    # Perform a grid search over the hyperparameters using cross-validation\n","    grid_search = GridSearchCV(xgb_model, param_grid, cv=3,verbose=2)\n","    grid_search.fit(x_train, y_train)\n","\n","    # Print the best hyperparameters and their corresponding score\n","    print(f\"Best hyperparameters: {grid_search.best_params_}\")\n","    print(f\"Best score: {grid_search.best_score_}\")\n","\n","    # Use cross-validation to calculate MSE, R2, and MAE\n","    scoring = ['neg_mean_squared_error', 'r2', 'neg_mean_absolute_error']\n","    cv_results = cross_validate(grid_search.best_estimator_, x_train, y_train, cv=3, scoring=scoring)\n","\n","    # Print the mean and standard deviation of each metric across the 5 folds\n","    mse_mean = -1 * cv_results['test_neg_mean_squared_error'].mean()\n","    mse_std = cv_results['test_neg_mean_squared_error'].std()\n","    r2_mean = cv_results['test_r2'].mean()\n","    r2_std = cv_results['test_r2'].std()\n","    mae_mean = -1 * cv_results['test_neg_mean_absolute_error'].mean()\n","    mae_std = cv_results['test_neg_mean_absolute_error'].std()\n","\n","    print(f\"MSE: {mse_mean:.2f} +/- {mse_std:.2f}\")\n","    print(f\"R2: {r2_mean:.2f} +/- {r2_std:.2f}\")\n","    print(f\"MAE: {mae_mean:.2f} +/- {mae_std:.2f}\")\n","\n","    # Return a ready-to-use model with the best hyperparameters\n","    best_model = grid_search.best_estimator_\n","    return best_model\n"],"metadata":{"id":"OHwV5GiN61Tq","executionInfo":{"status":"ok","timestamp":1677429413682,"user_tz":-120,"elapsed":2,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Example"],"metadata":{"id":"LxqR4vXS-5Z1"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"eoM9Y7eIYOfl","executionInfo":{"status":"ok","timestamp":1677429416419,"user_tz":-120,"elapsed":454,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"outputs":[],"source":["# Define input parameters\n","csv_path = '/content/data.csv'\n","feature_idx_i,feature_idx_f = 16,-2 # columns index of features\n","target_col = 'A' # labael column (regression)"]},{"cell_type":"code","source":["# Load data\n","data = load_data(csv_path, feature_idx_i,feature_idx_f, target_col)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"6VnenZtpd3e3","executionInfo":{"status":"ok","timestamp":1677429436100,"user_tz":-120,"elapsed":380,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}},"outputId":"c49cfdc4-0cd9-4718-ef2c-5de0f44993ea"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-629dbe82679f>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new_df[target_col] = df[target_col]\n"]},{"output_type":"execute_result","data":{"text/plain":["     397.32     400.2    403.09    405.97    408.85    411.74    414.63  \\\n","0  0.179808  0.152106  0.129191  0.115715  0.107613  0.102074  0.101501   \n","1  0.221156  0.186298  0.160032  0.146194  0.136323  0.128331  0.124891   \n","2  0.221893  0.185626  0.164002  0.154074  0.146511  0.137888  0.133002   \n","3  0.162126  0.129779  0.104428  0.089685  0.080833  0.075142  0.068085   \n","4  0.206857  0.164631  0.137415  0.118823  0.102912  0.097850  0.090029   \n","\n","     417.52     420.4    423.29  ...    978.88    981.96    985.05    988.13  \\\n","0  0.099727  0.096248  0.096929  ...  0.458213  0.464172  0.458520  0.462214   \n","1  0.121850  0.116359  0.114495  ...  0.717970  0.717748  0.722268  0.726763   \n","2  0.130920  0.128935  0.126446  ...  0.670528  0.675308  0.669332  0.689363   \n","3  0.063978  0.058188  0.054447  ...  0.570670  0.574177  0.580435  0.579218   \n","4  0.084146  0.077650  0.072445  ...  0.602451  0.609186  0.624415  0.622750   \n","\n","     991.22    994.31     997.4   1000.49   1003.58         A  \n","0  0.467727  0.467549  0.466043  0.471523  0.447471  2.017270  \n","1  0.738159  0.741649  0.739217  0.762054  0.622104  1.872474  \n","2  0.685825  0.698885  0.689815  0.705207  0.580815  2.043818  \n","3  0.582644  0.592902  0.597743  0.609343  0.480618  2.123489  \n","4  0.633371  0.640970  0.649146  0.659158  0.536100  2.122085  \n","\n","[5 rows x 205 columns]"],"text/html":["\n","  <div id=\"df-cc3ac75f-ea5e-4c17-a544-c750c454aef6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>397.32</th>\n","      <th>400.2</th>\n","      <th>403.09</th>\n","      <th>405.97</th>\n","      <th>408.85</th>\n","      <th>411.74</th>\n","      <th>414.63</th>\n","      <th>417.52</th>\n","      <th>420.4</th>\n","      <th>423.29</th>\n","      <th>...</th>\n","      <th>978.88</th>\n","      <th>981.96</th>\n","      <th>985.05</th>\n","      <th>988.13</th>\n","      <th>991.22</th>\n","      <th>994.31</th>\n","      <th>997.4</th>\n","      <th>1000.49</th>\n","      <th>1003.58</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.179808</td>\n","      <td>0.152106</td>\n","      <td>0.129191</td>\n","      <td>0.115715</td>\n","      <td>0.107613</td>\n","      <td>0.102074</td>\n","      <td>0.101501</td>\n","      <td>0.099727</td>\n","      <td>0.096248</td>\n","      <td>0.096929</td>\n","      <td>...</td>\n","      <td>0.458213</td>\n","      <td>0.464172</td>\n","      <td>0.458520</td>\n","      <td>0.462214</td>\n","      <td>0.467727</td>\n","      <td>0.467549</td>\n","      <td>0.466043</td>\n","      <td>0.471523</td>\n","      <td>0.447471</td>\n","      <td>2.017270</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.221156</td>\n","      <td>0.186298</td>\n","      <td>0.160032</td>\n","      <td>0.146194</td>\n","      <td>0.136323</td>\n","      <td>0.128331</td>\n","      <td>0.124891</td>\n","      <td>0.121850</td>\n","      <td>0.116359</td>\n","      <td>0.114495</td>\n","      <td>...</td>\n","      <td>0.717970</td>\n","      <td>0.717748</td>\n","      <td>0.722268</td>\n","      <td>0.726763</td>\n","      <td>0.738159</td>\n","      <td>0.741649</td>\n","      <td>0.739217</td>\n","      <td>0.762054</td>\n","      <td>0.622104</td>\n","      <td>1.872474</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.221893</td>\n","      <td>0.185626</td>\n","      <td>0.164002</td>\n","      <td>0.154074</td>\n","      <td>0.146511</td>\n","      <td>0.137888</td>\n","      <td>0.133002</td>\n","      <td>0.130920</td>\n","      <td>0.128935</td>\n","      <td>0.126446</td>\n","      <td>...</td>\n","      <td>0.670528</td>\n","      <td>0.675308</td>\n","      <td>0.669332</td>\n","      <td>0.689363</td>\n","      <td>0.685825</td>\n","      <td>0.698885</td>\n","      <td>0.689815</td>\n","      <td>0.705207</td>\n","      <td>0.580815</td>\n","      <td>2.043818</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.162126</td>\n","      <td>0.129779</td>\n","      <td>0.104428</td>\n","      <td>0.089685</td>\n","      <td>0.080833</td>\n","      <td>0.075142</td>\n","      <td>0.068085</td>\n","      <td>0.063978</td>\n","      <td>0.058188</td>\n","      <td>0.054447</td>\n","      <td>...</td>\n","      <td>0.570670</td>\n","      <td>0.574177</td>\n","      <td>0.580435</td>\n","      <td>0.579218</td>\n","      <td>0.582644</td>\n","      <td>0.592902</td>\n","      <td>0.597743</td>\n","      <td>0.609343</td>\n","      <td>0.480618</td>\n","      <td>2.123489</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.206857</td>\n","      <td>0.164631</td>\n","      <td>0.137415</td>\n","      <td>0.118823</td>\n","      <td>0.102912</td>\n","      <td>0.097850</td>\n","      <td>0.090029</td>\n","      <td>0.084146</td>\n","      <td>0.077650</td>\n","      <td>0.072445</td>\n","      <td>...</td>\n","      <td>0.602451</td>\n","      <td>0.609186</td>\n","      <td>0.624415</td>\n","      <td>0.622750</td>\n","      <td>0.633371</td>\n","      <td>0.640970</td>\n","      <td>0.649146</td>\n","      <td>0.659158</td>\n","      <td>0.536100</td>\n","      <td>2.122085</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 205 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc3ac75f-ea5e-4c17-a544-c750c454aef6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc3ac75f-ea5e-4c17-a544-c750c454aef6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc3ac75f-ea5e-4c17-a544-c750c454aef6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = split_data(data, target_col, test_size=0.3, random_state=42)\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPupoFVLDHpV","executionInfo":{"status":"ok","timestamp":1677429437622,"user_tz":-120,"elapsed":9,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}},"outputId":"ca750037-f367-4b70-fc73-5123a560347e"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((429, 204), (184, 204), (429,), (184,))"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["svr = svm_regression(X_train, y_train)"],"metadata":{"id":"SopKVY8o_LKQ"},"execution_count":null,"outputs":[]}]}