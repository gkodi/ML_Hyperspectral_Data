{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMiAN1aM0vBX0XTlgGI2CL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# AutoEncoder Feature Exraction\n","Hyperspectral images are usually high-dimensional and contain a large amount of redundant information. Therefore, feature extraction is essential for reducing the dimensionality of the data and selecting the most relevant features.\n","\n","In this code notebook, we will be discussing how to extract features from hyperspectral images using an autoencoder. An autoencoder is a type of neural network that can learn to encode high-dimensional data into a lower-dimensional representation. We will be using the autoencoder to generate new features that capture the essential information contained in the hyperspectral images.\n","\n","**Feature selection** and **feature extraction** are techniques used in machine learning to reduce the dimensionality of input data by selecting or transforming the most relevant features. Feature selection involves selecting a subset of the original features based on correlation with the target variable, while feature extraction transforms the original features into a new set of features. Feature extraction can be more effective when original features are highly correlated or when there are nonlinear relationships between features and the target variable. Both techniques can improve the performance of machine learning models.\n","\n","Here we use Autoencoder for feature extraction. Note that there is another notebook that deals with Autoencoder for feature selection.\n","\n","## Usage\n","\n","1. Use the functions and the example to load dataset, split to train/test, and get new dataset after extracting new features.\n","\n","2. The function *autoencoder_features()* based on basic architecture. You may change it.\n","\n","\n","\n"],"metadata":{"id":"9VBlu6uEQrGS"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"UA5ufV_qQksK","executionInfo":{"status":"ok","timestamp":1677180033782,"user_tz":-120,"elapsed":316,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import Model\n","from tensorflow.keras import Sequential\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU,Dropout"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3c4nWWFe_bOp","executionInfo":{"status":"ok","timestamp":1677180035411,"user_tz":-120,"elapsed":9,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"outputs":[],"source":["def load_data(csv_path, feature_col_start, feature_col_end, target_col):\n","    \"\"\"\n","    Load a CSV file into a Pandas DataFrame,drop Nan, and separate the feature and target columns.\n","\n","    Parameters:\n","        csv_path (str): Path to the CSV file to load.\n","        feature_col_start, feature_col_end, (ints): Range of column indices to use as features.\n","        target_col (str or int): Name or index of the column to use as target.\n","\n","    Returns:\n","        new_df: A df containing the features + labels DataFrame.\n","    \"\"\"\n","    # Load CSV into a Pandas DataFrame\n","    df = pd.read_csv(csv_path)\n","\n","    # drop nan\n","    df = df.dropna()\n","\n","    # Extract the feature and target columns\n","    new_df = df[df.columns[feature_col_start: feature_col_end]]\n","    new_df[target_col] = df[target_col]\n","\n","    return new_df"]},{"cell_type":"code","source":["def split_data(df, target_col, test_size=0.3, random_state=42):\n","    \"\"\"\n","    Splits the input DataFrame into training and testing sets.\n","    \n","    Parameters:\n","    -----------\n","    df (pandas DataFrame): The input DataFrame containing the features and target variable.\n","    target_col (str): The name of the target column in the DataFrame.\n","    test_size (float, optional): The proportion of the data to use for testing (default=0.3).\n","    random_state (int, optional): The random seed to use for the train-test split (default=42).\n","        \n","    Returns:\n","    --------\n","    X_train (pandas DataFrame): The training set features.     \n","    X_test (pandas DataFrame): The testing set features.        \n","    y_train (pandas Series): The training set target variable.\n","    y_test (pandas Series): The testing set target variable.\n","    \"\"\"\n","    # Extract the features and target variable from the DataFrame\n","    X = df.drop(columns=[target_col])\n","    y = df[target_col]\n","    \n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n","    \n","    # Return the training and testing sets\n","    return X_train, X_test, y_train, y_test"],"metadata":{"id":"R-7R0TX3bHNl","executionInfo":{"status":"ok","timestamp":1677180038108,"user_tz":-120,"elapsed":418,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def autoencoder_features(df,X_train,X_test,\n","                             target_col,\n","                             loss=\"mse\",optimizer=\"adam\",epochs=50, batch_size=32, validation_split=0.25):\n","    \"\"\"\n","    function that takes in a DataFrame (df) and a target column name (target_col),\n","    and returns DataFrame with new features generated by an Autoencoder model.\n","    Notice that you may change the net architecture.\n","        Parameters:\n","    -----------\n","    df (pandas DataFrame): The input DataFrame containing the features and target variable.\n","    X_train (pandas DataFrame): The training set features.     \n","    X_test (pandas DataFrame): The testing set features.  \n","    target_col (str): The name of the target column in the DataFrame.\n","    loss,optimizer,epochs,batch_size,batch_size: hyperparameters of the model.\n","    Returns:\n","    --------\n","    new_features_df (pandas DataFrame): DataFrame with new features generated by an Autoencoder model.     \n","    \"\"\"\n","    # split data into X (input) and y (output) \n","    X = df.drop(target_col, axis=1)\n","    y = df[target_col]\n","\n","    # implementation of the autoencoder model\n","    input = Input(shape=X_train.shape[1:])\n","    enc = Dense(64)(input)\n","    enc = LeakyReLU()(enc)\n","    enc = Dense(32)(enc)\n","    enc = LeakyReLU()(enc)\n","    # latent space with tanh\n","    latent_space = Dense(16, activation=\"tanh\")(enc)\n","\n","    dec = Dense(32)(latent_space)\n","    dec = LeakyReLU()(dec)\n","    dec = Dense(64)(dec)\n","    dec = LeakyReLU()(dec)\n","\n","    dec = Dense(units=X_train.shape[1], activation=\"relu\")(dec)\n","    # init model\n","    autoencoder = Model(input, dec)\n","    # compile model\n","    autoencoder.compile(optimizer=optimizer, metrics=[\"mse\"], loss=loss)\n","    # train model\n","    autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n","    encoder = Model(input, latent_space)\n","    # generate new features using the encoder\n","    new_features = encoder.predict(X)\n","    # create a DataFrame with new features and concatenate it with the original DataFrame\n","    new_features_df = pd.DataFrame(new_features, columns=[f'feature_{i}' for i in range(new_features.shape[1])])\n","    \n","    return new_features_df"],"metadata":{"id":"751VT_xar4HD","executionInfo":{"status":"ok","timestamp":1677180040457,"user_tz":-120,"elapsed":367,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Example"],"metadata":{"id":"T1jxYRhNQ_Wh"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"eoM9Y7eIYOfl","executionInfo":{"status":"ok","timestamp":1677180042232,"user_tz":-120,"elapsed":14,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}}},"outputs":[],"source":["# Define input parameters\n","csv_path = '/content/data.csv'\n","feature_idx_i,feature_idx_f = 16,-2 # columns index of features\n","target_col = 'A' # labael column (regression)"]},{"cell_type":"code","source":["# Load data\n","data = load_data(csv_path, feature_idx_i,feature_idx_f, target_col)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"6VnenZtpd3e3","executionInfo":{"status":"ok","timestamp":1677180044308,"user_tz":-120,"elapsed":989,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}},"outputId":"dacc41a3-fc97-4e89-fe6b-a9bd44b44989"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-629dbe82679f>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new_df[target_col] = df[target_col]\n"]},{"output_type":"execute_result","data":{"text/plain":["     397.32     400.2    403.09    405.97    408.85    411.74    414.63  \\\n","0  0.179808  0.152106  0.129191  0.115715  0.107613  0.102074  0.101501   \n","1  0.221156  0.186298  0.160032  0.146194  0.136323  0.128331  0.124891   \n","2  0.221893  0.185626  0.164002  0.154074  0.146511  0.137888  0.133002   \n","3  0.162126  0.129779  0.104428  0.089685  0.080833  0.075142  0.068085   \n","4  0.206857  0.164631  0.137415  0.118823  0.102912  0.097850  0.090029   \n","\n","     417.52     420.4    423.29  ...    978.88    981.96    985.05    988.13  \\\n","0  0.099727  0.096248  0.096929  ...  0.458213  0.464172  0.458520  0.462214   \n","1  0.121850  0.116359  0.114495  ...  0.717970  0.717748  0.722268  0.726763   \n","2  0.130920  0.128935  0.126446  ...  0.670528  0.675308  0.669332  0.689363   \n","3  0.063978  0.058188  0.054447  ...  0.570670  0.574177  0.580435  0.579218   \n","4  0.084146  0.077650  0.072445  ...  0.602451  0.609186  0.624415  0.622750   \n","\n","     991.22    994.31     997.4   1000.49   1003.58         A  \n","0  0.467727  0.467549  0.466043  0.471523  0.447471  2.017270  \n","1  0.738159  0.741649  0.739217  0.762054  0.622104  1.872474  \n","2  0.685825  0.698885  0.689815  0.705207  0.580815  2.043818  \n","3  0.582644  0.592902  0.597743  0.609343  0.480618  2.123489  \n","4  0.633371  0.640970  0.649146  0.659158  0.536100  2.122085  \n","\n","[5 rows x 205 columns]"],"text/html":["\n","  <div id=\"df-c7873323-f60e-48c5-8088-4d1abb1af37a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>397.32</th>\n","      <th>400.2</th>\n","      <th>403.09</th>\n","      <th>405.97</th>\n","      <th>408.85</th>\n","      <th>411.74</th>\n","      <th>414.63</th>\n","      <th>417.52</th>\n","      <th>420.4</th>\n","      <th>423.29</th>\n","      <th>...</th>\n","      <th>978.88</th>\n","      <th>981.96</th>\n","      <th>985.05</th>\n","      <th>988.13</th>\n","      <th>991.22</th>\n","      <th>994.31</th>\n","      <th>997.4</th>\n","      <th>1000.49</th>\n","      <th>1003.58</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.179808</td>\n","      <td>0.152106</td>\n","      <td>0.129191</td>\n","      <td>0.115715</td>\n","      <td>0.107613</td>\n","      <td>0.102074</td>\n","      <td>0.101501</td>\n","      <td>0.099727</td>\n","      <td>0.096248</td>\n","      <td>0.096929</td>\n","      <td>...</td>\n","      <td>0.458213</td>\n","      <td>0.464172</td>\n","      <td>0.458520</td>\n","      <td>0.462214</td>\n","      <td>0.467727</td>\n","      <td>0.467549</td>\n","      <td>0.466043</td>\n","      <td>0.471523</td>\n","      <td>0.447471</td>\n","      <td>2.017270</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.221156</td>\n","      <td>0.186298</td>\n","      <td>0.160032</td>\n","      <td>0.146194</td>\n","      <td>0.136323</td>\n","      <td>0.128331</td>\n","      <td>0.124891</td>\n","      <td>0.121850</td>\n","      <td>0.116359</td>\n","      <td>0.114495</td>\n","      <td>...</td>\n","      <td>0.717970</td>\n","      <td>0.717748</td>\n","      <td>0.722268</td>\n","      <td>0.726763</td>\n","      <td>0.738159</td>\n","      <td>0.741649</td>\n","      <td>0.739217</td>\n","      <td>0.762054</td>\n","      <td>0.622104</td>\n","      <td>1.872474</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.221893</td>\n","      <td>0.185626</td>\n","      <td>0.164002</td>\n","      <td>0.154074</td>\n","      <td>0.146511</td>\n","      <td>0.137888</td>\n","      <td>0.133002</td>\n","      <td>0.130920</td>\n","      <td>0.128935</td>\n","      <td>0.126446</td>\n","      <td>...</td>\n","      <td>0.670528</td>\n","      <td>0.675308</td>\n","      <td>0.669332</td>\n","      <td>0.689363</td>\n","      <td>0.685825</td>\n","      <td>0.698885</td>\n","      <td>0.689815</td>\n","      <td>0.705207</td>\n","      <td>0.580815</td>\n","      <td>2.043818</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.162126</td>\n","      <td>0.129779</td>\n","      <td>0.104428</td>\n","      <td>0.089685</td>\n","      <td>0.080833</td>\n","      <td>0.075142</td>\n","      <td>0.068085</td>\n","      <td>0.063978</td>\n","      <td>0.058188</td>\n","      <td>0.054447</td>\n","      <td>...</td>\n","      <td>0.570670</td>\n","      <td>0.574177</td>\n","      <td>0.580435</td>\n","      <td>0.579218</td>\n","      <td>0.582644</td>\n","      <td>0.592902</td>\n","      <td>0.597743</td>\n","      <td>0.609343</td>\n","      <td>0.480618</td>\n","      <td>2.123489</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.206857</td>\n","      <td>0.164631</td>\n","      <td>0.137415</td>\n","      <td>0.118823</td>\n","      <td>0.102912</td>\n","      <td>0.097850</td>\n","      <td>0.090029</td>\n","      <td>0.084146</td>\n","      <td>0.077650</td>\n","      <td>0.072445</td>\n","      <td>...</td>\n","      <td>0.602451</td>\n","      <td>0.609186</td>\n","      <td>0.624415</td>\n","      <td>0.622750</td>\n","      <td>0.633371</td>\n","      <td>0.640970</td>\n","      <td>0.649146</td>\n","      <td>0.659158</td>\n","      <td>0.536100</td>\n","      <td>2.122085</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 205 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7873323-f60e-48c5-8088-4d1abb1af37a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7873323-f60e-48c5-8088-4d1abb1af37a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7873323-f60e-48c5-8088-4d1abb1af37a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = split_data(data, target_col, test_size=0.3, random_state=42)\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPupoFVLDHpV","executionInfo":{"status":"ok","timestamp":1677180045361,"user_tz":-120,"elapsed":6,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}},"outputId":"5fe7964e-77f3-4829-ac52-b3d5648f2850"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((429, 204), (184, 204), (429,), (184,))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df_features = autoencoder_features(data,X_train,X_test,\n","                             target_col,\n","                             loss=\"mse\",optimizer=\"adam\",epochs=50, batch_size=32, validation_split=0.25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqgKWxYmTsjb","executionInfo":{"status":"ok","timestamp":1677180089751,"user_tz":-120,"elapsed":7732,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}},"outputId":"60f802b7-f6e9-4520-85e3-370d5a6073b6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","11/11 [==============================] - 2s 48ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 0.1139 - val_mse: 0.1139\n","Epoch 2/50\n","11/11 [==============================] - 0s 11ms/step - loss: 0.0915 - mse: 0.0915 - val_loss: 0.0840 - val_mse: 0.0840\n","Epoch 3/50\n","11/11 [==============================] - 0s 11ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0761 - val_mse: 0.0761\n","Epoch 4/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0738 - val_mse: 0.0738\n","Epoch 5/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0728 - val_mse: 0.0728\n","Epoch 6/50\n","11/11 [==============================] - 0s 11ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0697 - val_mse: 0.0697\n","Epoch 7/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0669 - val_mse: 0.0669\n","Epoch 8/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0654 - val_mse: 0.0654\n","Epoch 9/50\n","11/11 [==============================] - 0s 9ms/step - loss: 0.0601 - mse: 0.0601 - val_loss: 0.0650 - val_mse: 0.0650\n","Epoch 10/50\n","11/11 [==============================] - 0s 12ms/step - loss: 0.0598 - mse: 0.0598 - val_loss: 0.0650 - val_mse: 0.0650\n","Epoch 11/50\n","11/11 [==============================] - 0s 11ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0655 - val_mse: 0.0655\n","Epoch 12/50\n","11/11 [==============================] - 0s 12ms/step - loss: 0.0601 - mse: 0.0601 - val_loss: 0.0655 - val_mse: 0.0655\n","Epoch 13/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0647 - val_mse: 0.0647\n","Epoch 14/50\n","11/11 [==============================] - 0s 9ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0647 - val_mse: 0.0647\n","Epoch 15/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0647 - val_mse: 0.0647\n","Epoch 16/50\n","11/11 [==============================] - 0s 10ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0646 - val_mse: 0.0646\n","Epoch 17/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0646 - val_mse: 0.0646\n","Epoch 18/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0623 - val_mse: 0.0623\n","Epoch 19/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0586 - val_mse: 0.0586\n","Epoch 20/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0556 - val_mse: 0.0556\n","Epoch 21/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0519 - val_mse: 0.0519\n","Epoch 22/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0514 - val_mse: 0.0514\n","Epoch 23/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0509 - val_mse: 0.0509\n","Epoch 24/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0509 - val_mse: 0.0509\n","Epoch 25/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 26/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0509 - val_mse: 0.0509\n","Epoch 27/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0509 - val_mse: 0.0509\n","Epoch 28/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0510 - val_mse: 0.0510\n","Epoch 29/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 30/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 31/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 32/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 33/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 34/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 35/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0509 - val_mse: 0.0509\n","Epoch 36/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 37/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 38/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0508 - val_mse: 0.0508\n","Epoch 39/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 40/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 41/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 42/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 43/50\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 44/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 45/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 46/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 47/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 48/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 49/50\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0507 - val_mse: 0.0507\n","Epoch 50/50\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0507 - val_mse: 0.0507\n","20/20 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["df_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"kEJf8XUcrBwl","executionInfo":{"status":"ok","timestamp":1677180091293,"user_tz":-120,"elapsed":11,"user":{"displayName":"Yehuda Toungshtein","userId":"04524178467024584659"}},"outputId":"5167de9a-efcd-4d49-9383-2ab0d2491afd"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n","0    -0.226710   0.367379  -0.453775  -0.243337  -0.379570   0.337105   \n","1    -0.392412   0.511957  -0.595188  -0.408742  -0.518194   0.472658   \n","2    -0.363270   0.514233  -0.609711  -0.379850  -0.529868   0.466887   \n","3    -0.367679   0.340414  -0.403759  -0.367892  -0.332654   0.357605   \n","4    -0.392967   0.387700  -0.458593  -0.391254  -0.385409   0.390036   \n","..         ...        ...        ...        ...        ...        ...   \n","608  -0.368498   0.383428  -0.457780  -0.383372  -0.376442   0.392817   \n","609  -0.154761   0.179125  -0.194564  -0.152249  -0.139075   0.187430   \n","610  -0.292893   0.428690  -0.482035  -0.303205  -0.418158   0.386230   \n","611  -0.255581   0.203358  -0.252723  -0.250916  -0.190387   0.236246   \n","612  -0.147348   0.205978  -0.246692  -0.148708  -0.189793   0.195789   \n","\n","     feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n","0    -0.258442  -0.096716   0.249617   0.161003    0.261766   -0.237449   \n","1    -0.407552  -0.267419   0.411955   0.280689    0.442423   -0.402998   \n","2    -0.395367  -0.213084   0.396524   0.261208    0.404896   -0.392904   \n","3    -0.325814  -0.322821   0.376223   0.203409    0.430623   -0.296424   \n","4    -0.353436  -0.334596   0.399288   0.224156    0.448335   -0.336498   \n","..         ...        ...        ...        ...         ...         ...   \n","608  -0.358337  -0.324440   0.378109   0.215161    0.441282   -0.316237   \n","609  -0.128001  -0.085523   0.136962   0.094085    0.190587   -0.087723   \n","610  -0.297801  -0.159050   0.278662   0.238146    0.325819   -0.298994   \n","611  -0.209040  -0.225981   0.263876   0.106747    0.317439   -0.162832   \n","612  -0.132753  -0.061581   0.144853   0.086545    0.171795   -0.108175   \n","\n","     feature_12  feature_13  feature_14  feature_15  \n","0     -0.425229   -0.161112   -0.234261   -0.012255  \n","1     -0.538262   -0.311342   -0.356958   -0.109674  \n","2     -0.568253   -0.274818   -0.347737   -0.041594  \n","3     -0.280870   -0.294212   -0.271220   -0.271321  \n","4     -0.339386   -0.307971   -0.292036   -0.255892  \n","..          ...         ...         ...         ...  \n","608   -0.335153   -0.291110   -0.282997   -0.248043  \n","609   -0.152354   -0.111654   -0.121720   -0.135936  \n","610   -0.462407   -0.236915   -0.282680   -0.065743  \n","611   -0.133378   -0.191363   -0.162778   -0.239692  \n","612   -0.210550   -0.093998   -0.121565   -0.077611  \n","\n","[613 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-58c4a73b-6d5b-4e30-8a85-13d137c426a1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature_0</th>\n","      <th>feature_1</th>\n","      <th>feature_2</th>\n","      <th>feature_3</th>\n","      <th>feature_4</th>\n","      <th>feature_5</th>\n","      <th>feature_6</th>\n","      <th>feature_7</th>\n","      <th>feature_8</th>\n","      <th>feature_9</th>\n","      <th>feature_10</th>\n","      <th>feature_11</th>\n","      <th>feature_12</th>\n","      <th>feature_13</th>\n","      <th>feature_14</th>\n","      <th>feature_15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.226710</td>\n","      <td>0.367379</td>\n","      <td>-0.453775</td>\n","      <td>-0.243337</td>\n","      <td>-0.379570</td>\n","      <td>0.337105</td>\n","      <td>-0.258442</td>\n","      <td>-0.096716</td>\n","      <td>0.249617</td>\n","      <td>0.161003</td>\n","      <td>0.261766</td>\n","      <td>-0.237449</td>\n","      <td>-0.425229</td>\n","      <td>-0.161112</td>\n","      <td>-0.234261</td>\n","      <td>-0.012255</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.392412</td>\n","      <td>0.511957</td>\n","      <td>-0.595188</td>\n","      <td>-0.408742</td>\n","      <td>-0.518194</td>\n","      <td>0.472658</td>\n","      <td>-0.407552</td>\n","      <td>-0.267419</td>\n","      <td>0.411955</td>\n","      <td>0.280689</td>\n","      <td>0.442423</td>\n","      <td>-0.402998</td>\n","      <td>-0.538262</td>\n","      <td>-0.311342</td>\n","      <td>-0.356958</td>\n","      <td>-0.109674</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.363270</td>\n","      <td>0.514233</td>\n","      <td>-0.609711</td>\n","      <td>-0.379850</td>\n","      <td>-0.529868</td>\n","      <td>0.466887</td>\n","      <td>-0.395367</td>\n","      <td>-0.213084</td>\n","      <td>0.396524</td>\n","      <td>0.261208</td>\n","      <td>0.404896</td>\n","      <td>-0.392904</td>\n","      <td>-0.568253</td>\n","      <td>-0.274818</td>\n","      <td>-0.347737</td>\n","      <td>-0.041594</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.367679</td>\n","      <td>0.340414</td>\n","      <td>-0.403759</td>\n","      <td>-0.367892</td>\n","      <td>-0.332654</td>\n","      <td>0.357605</td>\n","      <td>-0.325814</td>\n","      <td>-0.322821</td>\n","      <td>0.376223</td>\n","      <td>0.203409</td>\n","      <td>0.430623</td>\n","      <td>-0.296424</td>\n","      <td>-0.280870</td>\n","      <td>-0.294212</td>\n","      <td>-0.271220</td>\n","      <td>-0.271321</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.392967</td>\n","      <td>0.387700</td>\n","      <td>-0.458593</td>\n","      <td>-0.391254</td>\n","      <td>-0.385409</td>\n","      <td>0.390036</td>\n","      <td>-0.353436</td>\n","      <td>-0.334596</td>\n","      <td>0.399288</td>\n","      <td>0.224156</td>\n","      <td>0.448335</td>\n","      <td>-0.336498</td>\n","      <td>-0.339386</td>\n","      <td>-0.307971</td>\n","      <td>-0.292036</td>\n","      <td>-0.255892</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>-0.368498</td>\n","      <td>0.383428</td>\n","      <td>-0.457780</td>\n","      <td>-0.383372</td>\n","      <td>-0.376442</td>\n","      <td>0.392817</td>\n","      <td>-0.358337</td>\n","      <td>-0.324440</td>\n","      <td>0.378109</td>\n","      <td>0.215161</td>\n","      <td>0.441282</td>\n","      <td>-0.316237</td>\n","      <td>-0.335153</td>\n","      <td>-0.291110</td>\n","      <td>-0.282997</td>\n","      <td>-0.248043</td>\n","    </tr>\n","    <tr>\n","      <th>609</th>\n","      <td>-0.154761</td>\n","      <td>0.179125</td>\n","      <td>-0.194564</td>\n","      <td>-0.152249</td>\n","      <td>-0.139075</td>\n","      <td>0.187430</td>\n","      <td>-0.128001</td>\n","      <td>-0.085523</td>\n","      <td>0.136962</td>\n","      <td>0.094085</td>\n","      <td>0.190587</td>\n","      <td>-0.087723</td>\n","      <td>-0.152354</td>\n","      <td>-0.111654</td>\n","      <td>-0.121720</td>\n","      <td>-0.135936</td>\n","    </tr>\n","    <tr>\n","      <th>610</th>\n","      <td>-0.292893</td>\n","      <td>0.428690</td>\n","      <td>-0.482035</td>\n","      <td>-0.303205</td>\n","      <td>-0.418158</td>\n","      <td>0.386230</td>\n","      <td>-0.297801</td>\n","      <td>-0.159050</td>\n","      <td>0.278662</td>\n","      <td>0.238146</td>\n","      <td>0.325819</td>\n","      <td>-0.298994</td>\n","      <td>-0.462407</td>\n","      <td>-0.236915</td>\n","      <td>-0.282680</td>\n","      <td>-0.065743</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>-0.255581</td>\n","      <td>0.203358</td>\n","      <td>-0.252723</td>\n","      <td>-0.250916</td>\n","      <td>-0.190387</td>\n","      <td>0.236246</td>\n","      <td>-0.209040</td>\n","      <td>-0.225981</td>\n","      <td>0.263876</td>\n","      <td>0.106747</td>\n","      <td>0.317439</td>\n","      <td>-0.162832</td>\n","      <td>-0.133378</td>\n","      <td>-0.191363</td>\n","      <td>-0.162778</td>\n","      <td>-0.239692</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>-0.147348</td>\n","      <td>0.205978</td>\n","      <td>-0.246692</td>\n","      <td>-0.148708</td>\n","      <td>-0.189793</td>\n","      <td>0.195789</td>\n","      <td>-0.132753</td>\n","      <td>-0.061581</td>\n","      <td>0.144853</td>\n","      <td>0.086545</td>\n","      <td>0.171795</td>\n","      <td>-0.108175</td>\n","      <td>-0.210550</td>\n","      <td>-0.093998</td>\n","      <td>-0.121565</td>\n","      <td>-0.077611</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>613 rows × 16 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58c4a73b-6d5b-4e30-8a85-13d137c426a1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-58c4a73b-6d5b-4e30-8a85-13d137c426a1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-58c4a73b-6d5b-4e30-8a85-13d137c426a1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]}]}